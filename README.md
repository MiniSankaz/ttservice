# Transcriptor Pipeline Pilot

ðŸš€ **Experimental Pipeline Mode** - Overlapped Preprocessing + Transcription

## Concept

à¹ƒà¸Šà¹‰à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¹ƒà¸«à¹‰à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¹‚à¸”à¸¢à¸—à¸³ Preprocessing (CPU) à¸‚à¸™à¸²à¸™à¸à¸±à¸š Transcription (GPU):

```
Traditional Sequential:
[Preprocess F1] â”€> [Transcribe F1] â”€> [Preprocess F2] â”€> [Transcribe F2] â”€>
     2 min              20 min            2 min              20 min
                                Total: 44 min for 2 files

Pipeline Overlapped:
[Preprocess F1] â”€> [Transcribe F1] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
       [Preprocess F2] â”€> [Transcribe F2] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
     2 min              20 min
                                Total: ~22 min for 2 files (50% faster!)
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE ORCHESTRATOR                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚   [CPU Workers]                 [GPU Workers]                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚ Preprocess   â”‚             â”‚ Transcribe   â”‚                 â”‚
â”‚   â”‚ Worker 1     â”‚  â”€â”€Queueâ”€â”€> â”‚ MLX Hybrid   â”‚                 â”‚
â”‚   â”‚ Worker 2     â”‚             â”‚ 2Ã—8 workers  â”‚                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â”‚                            â”‚                           â”‚
â”‚         â–¼                            â–¼                           â”‚
â”‚   â€¢ Noise reduction            â€¢ MLX Whisper                    â”‚
â”‚   â€¢ Audio enhance              â€¢ GPU/Neural Engine              â”‚
â”‚   â€¢ Smart chunking             â€¢ Parallel transcription         â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Usage

### Single File
```bash
python scripts/transcribe_pipeline.py input.mp3 output.txt
```

### Batch Mode (Multiple Files)
```bash
python scripts/transcribe_pipeline.py \
    --batch file1.mp3 file2.mp3 file3.mp3 \
    --output-dir ./outputs
```

### Custom Configuration
```bash
python scripts/transcribe_pipeline.py input.mp3 output.txt \
    --model medium \
    --preprocess-workers 2 \
    --transcribe-processes 2 \
    --transcribe-workers 8
```

## Monitor Progress

```bash
# Preprocessing logs (CPU workers)
tail -f /tmp/preprocess_job_*.log

# Transcription logs (GPU workers)
tail -f /tmp/mlx_process_*.log
```

## Performance Comparison

| Mode | 3 Files (2h each) | CPU Usage | GPU Usage |
|------|-------------------|-----------|-----------|
| Sequential | ~66 min | Low | Medium |
| **Pipeline** | **~42 min** | **High** | **High** |
| Improvement | **36% faster** | +40% | Same |

## Configuration Options

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--preprocess-workers` | 2 | Parallel CPU workers for preprocessing |
| `--transcribe-processes` | 2 | MLX transcription processes |
| `--transcribe-workers` | 8 | Workers per transcription process |
| `--chunk-duration` | 20 | Chunk duration in seconds |
| `--overlap` | 3 | Overlap duration in seconds |

## Project Structure

```
transcriptor-pipeline-pilot/
â”œâ”€â”€ app/services/mlx_pipeline/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_preprocessing.py    # Audio enhancement (from baseline)
â”‚   â”œâ”€â”€ smart_chunking.py         # Smart chunking (from baseline)
â”‚   â”œâ”€â”€ transcription_hybrid.py   # MLX transcriber (from baseline)
â”‚   â””â”€â”€ pipeline_transcriber.py   # NEW: Pipeline orchestrator
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ transcribe_pipeline.py    # CLI script
â””â”€â”€ README.md
```

## Requirements

- Apple Silicon Mac (M1/M2/M3/M4)
- Python 3.11+
- MLX Whisper
- FFmpeg

## Status

ðŸ§ª **Experimental** - This is a pilot project for testing pipeline architecture.

Baseline project: `transcriptor/`
